{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Model Training with NeuroScribe\n",
    "\n",
    "This notebook demonstrates how to train a simple convolutional neural network (CNN) on the MNIST dataset using the NeuroScribe framework.\n",
    "\n",
    "## Overview\n",
    "- **Dataset**: MNIST (handwritten digits)\n",
    "- **Framework**: NeuroScribe\n",
    "- **Model**: Convolutional Neural Network (CNN) with LeakyReLU activations\n",
    "- **Optimizer**: Adam\n",
    "- **Loss Function**: Mean Squared Error (MSE)\n",
    "- **Device**: CUDA\n",
    "\n",
    "## Steps\n",
    "1. **Data Preparation**: Load and preprocess the MNIST dataset.\n",
    "2. **Model Definition**: Define the CNN architecture using NeuroScribe.\n",
    "3. **Training**: Train the model on the training dataset.\n",
    "4. **Evaluation**: Evaluate the model's accuracy on the test dataset.\n",
    "5. **Visualization**: Plot training loss and accuracy over epochs.\n",
    "6. **Saving the Model**: Save the trained model for future use.\n",
    "\n",
    "## Prerequisites\n",
    "- Ensure you have installed `NeuroScribe`.\n",
    "- A CUDA-compatible GPU.\n",
    "\n",
    "## Usage\n",
    "Follow the steps in this notebook to train a CNN on the MNIST dataset and visualize the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cupy as cp\n",
    "import neuroscribe as ns\n",
    "import neuroscribe.nn as nn\n",
    "import neuroscribe.optim as optim\n",
    "from neuroscribe.utils.data import data_loader, datasets\n",
    "from neuroscribe.utils.data.transforms import Compose, Normalize\n",
    "from neuroscribe.utils.metrics import accuracy_score\n",
    "from neuroscribe.utils.plot import plot_loss, plot_accuracy\n",
    "\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.fc1 = nn.Linear(32 * 28 * 28, 512, bias=True)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(512, 10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = x.reshape((-1, 32 * 28 * 28))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    \"\"\"Convert labels to one-hot encoding.\"\"\"\n",
    "    labels = labels.data.reshape(-1).astype('int32')\n",
    "    return ns.tensor(cp.eye(num_classes)[labels], requires_grad=True, device='cuda')\n",
    "\n",
    "\n",
    "def evaluate_accuracy(model, data_loader):\n",
    "    \"\"\"Evaluate the accuracy of the model on the given data loader.\"\"\"\n",
    "    score = 0\n",
    "    num_batches = 0\n",
    "    model.eval()\n",
    "    for inputs, targets in data_loader:\n",
    "        inputs = inputs.reshape((-1, 1, 28, 28))\n",
    "        targets = one_hot_encode(targets)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        predicted = outputs.argmax(dim=1)\n",
    "        actual = targets.argmax(dim=1)\n",
    "        local_score = accuracy_score(actual, predicted)\n",
    "        score += local_score.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return 100.0 * score / num_batches\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, inputs, targets):\n",
    "    \"\"\"Train the model for one batch.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set up data transformation\n",
    "    transform = Compose([Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    # Load datasets\n",
    "    training_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "    test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Set up data loaders\n",
    "    train_data_loader = data_loader.DataLoader(training_data, batch_size=128, shuffle=True, train=True)\n",
    "    test_data_loader = data_loader.DataLoader(test_data, batch_size=128, shuffle=False, train=False)\n",
    "\n",
    "    train_data_loader.to('cuda')\n",
    "    test_data_loader.to('cuda')\n",
    "\n",
    "    # Initialize model, optimizer, and loss function\n",
    "    model = MNIST()\n",
    "    model.to('cuda')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "    num_epochs = 8\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, targets in train_data_loader:\n",
    "            inputs = inputs.reshape((-1, 1, 28, 28))\n",
    "            targets = one_hot_encode(targets, num_classes=10)\n",
    "            loss = train(model, optimizer, criterion, inputs, targets)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        average_loss = epoch_loss / len(train_data_loader)\n",
    "        train_losses.append(average_loss)\n",
    "        accuracy = evaluate_accuracy(model, test_data_loader)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {average_loss:.4f} - Accuracy on test data: {accuracy:.2f}%')\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Training on {model._device} took: {end_time - start_time:.2f}s\")\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plot_loss(train_losses, title=\"Training Loss\")\n",
    "    plot_accuracy(accuracies, title=\"Accuracy\")\n",
    "\n",
    "    # Save the trained model\n",
    "    ns.save(model, filename=\"mnist\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
